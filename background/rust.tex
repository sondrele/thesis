% !TEX root = ../main.tex

\section{The Rust Programming Language} % (fold)
\label{sub:the_rust_programming_language}

Rust \cite{web:rust_lang} is a new open source systems programming language developed with backing from the Mozilla Foundation \cite{web:mozilla_foundation}.
Rust is a strongly and statically typed, multi-paradigm programming language.
The language borrows many traits and features from other programming languages, some of which is described in the following sections.

Over the course of Rust's development, the language has set out to solve two major problems concerning both safety and concurrency.
It is designed to support concurrency and parallelism and take full utilization of the underlying hardware, while making strong guarantees about memory safety and isolation, without sacrificing performance.

\subsection{Language Features}
\label{ssub:rust:features}

This section describes a few key language features of Rust that are not present in the procedural paradigm usually found in embedded programming.
The language is multi-paradigm and therefore offers a wider range of language constructs.

\subsubsection{Variables and Bindings}

Rust features a handful of different data types, all which can be assigned to a \emph{variable} by using a \emph{binding}.
The most important types are described in the following sections, but we will first look at how variables work.
A value gets bound to a variable by utilizing the \texttt{let} keyword.
A variable in Rust has a name and a value, much like other programming languages, but there is a distinct difference between the \emph{mutability} of those variables.

With a mutable variable binding, it is possible to change the value of the variable.
However, if we try to change the value of an immutable variable binding, Rust will give us a compile-time error.
The example code in \autoref{lst:rust_variable_bindings} shows how to declare both mutable and immutable variables and how to modify their values.
The example will not work because we try to change the value of an immutable variable.

\begin{listing}[H]
  \begin{minted}{rust}
    // bind the value `5' to the immutable variable `a'
    let a: i32 = 5;
    // bind the value `10' to the mutable variable `a'
    let mut b = 10;
    b = a; // change the value of `b'
    a = b; // <- error: re-assignment of immutable variable `a'
  \end{minted}
  \caption{Variable bindings}
  \label{lst:rust_variable_bindings}
\end{listing}

An important part of variable bindings is Rust's way to automatically infer the data type of the variables.
We can see from the example that \texttt{a} is defined to be a 32-bit integer with the value 5, and because the variable \texttt{b} later gets assigned to \texttt{a}'s value, Rust will automatically infer \texttt{b} to be of the same type.

\subsubsection{Sum types - Enum}

A sum type, also known as a tagged union, or an \texttt{enum} in Rust, is a data structure that is used to hold only one out of a small set of possible values.
Rust's \texttt{enum} construct is a class of \emph{algebraic data types} that are common in functional programming languages, which means that its actual type is formed by combining together other types.
This makes the \texttt{enum} a powerful feature of the language that can be used to deterministically limit the set of possible outcomes for a type.
\autoref{lst:rust:option} shows the definition of one of Rust's most commonly used types that is used extensively throughout its standard library and other third party libraries and applications.

\begin{listing}[H]
  \begin{minted}{rust}
    pub enum Option<T> {
      Some(T),
      None,
    }
  \end{minted}
  \caption{Definition of Option}
  \label{lst:rust:option}
\end{listing}

Every \texttt{Option} variable is an \texttt{enum} that can either have the algebraic value \texttt{Some} or the \emph{named value} \texttt{None}.
If the variable is is \texttt{Some}, the definition also says that it needs to contain another type \texttt{T}.
This is also an example of generics in Rust, \texttt{T} can be anything, e.g. an integer, a string, or a user defined type.
The \texttt{Option} type is analogous with a normal C pointer value, which either has the value 0, or \texttt{null} (analogous to \texttt{None}), or a value that that points to a structure at a place in memory (analogous to \texttt{Some}).
Even though the \texttt{Option} is analogous to a C pointer, it is important to note their differences.
It acts more like a wrapper around a potential other value and its internal type is not \emph{directly} accessible, which encourages the programmer to handle the cases where it might be \texttt{None}.
The usage of \texttt{enum} types described in this section become very expressive in combination with \emph{match expressions}, as discussed in \autoref{sub:pattern_matching}.

\subsubsection{Case Study - List}

A canonical example of a Sum type is the representation of a linked list in \autoref{lst:rust:list}.
Each list item is either a value and a pointer to the next item, as the \textbf{Cons}, or a termination value as \textbf{Nil}.

\begin{listing}[H]
  \begin{minted}{rust}
    enum List<T> {
      Cons(T, Box<List>),
      Nil,
    }
  \end{minted}
  \caption{Definition of Linked List}
  \label{lst:rust:list}
\end{listing}

\subsubsection{Structs}
\label{ssub:structs}

\texttt{structs} in Rust are similar to that of C, and is a way of creating more advanced data types than \texttt{primitives} or \texttt{enums}.
With a \texttt{struct} it is possible to combine multiple variables into a single type, each of them identified with its own name.
An example of a \texttt{struct} is shown in \autoref{lst:book_struct}, everyone that knows C will see the similarity of the \texttt{struct} definition, but there are also a couple of extra things to notice from the example.
Everything in Rust is \emph{private} by default, the \texttt{pub} keywords on type definitions and member fields make them \emph{publicly accessible}.
The \texttt{impl} keyword lets us implement member functions for the \texttt{Book}, similar to class-declarations in C++ and other object-oriented languages.

\begin{listing}[H]
  \begin{minted}{rust}
    pub struct Book {
      pub name: String,
      pub pages: u32,
    }

    impl Book {
      pub fn info(&self) {
        println!("{} has {} pages.", self.name, self.pages);
      }
    }
  \end{minted}
  \caption{Struct definition and implementation}
  \label{lst:book_struct}
\end{listing}

\subsubsection{Pattern Matching and Destructuring}
\label{sub:pattern_matching}

Pattern matching is a powerful language construct of Rust that resembles the \texttt{switch} statement from C.
It is possible to match against any value or variable in the language, and branch to different blocks of code based on the outcome of the \texttt{match}.
Another important feature of the \texttt{match} statement is that it needs to be \emph{exhaustive}, this means that all possible outcomes of a \texttt{match} need to be considered, otherwise Rust will issue an error during compilation.
This is contrary to C, where only primitive values can be used in a \texttt{switch} statement, and there is no requirement to cover all switch cases, i.e. the \texttt{default} keyword is not required.

An example of pattern matching on the \texttt{Option} type is given in \autoref{lst:rust:match}.
We can see from the example that the match can be used to \emph{destructure} the matching value in order to get hold of its enclosing value.
We can also see that both \texttt{Some} and \texttt{None}, i.e. all possible outcomes of the \texttt{Option}, are being matched against.
% In Listing \ref{lst:rust:match} the Option \texttt{Some(42)} is checked against the patterns in the match expression.
% As the first pattern matches the value, the number \texttt{42} is bound to the variable number and the \texttt{println} function is executed.

\begin{listing}[H]
  \begin{minted}{rust}
    // Bind the value `Some(42)' to the variable `num'
    let num: Option<u32> = Some(42);

    match num {
      // Bind the Option's enclosing value to the variable
      // `number' and print its value
      Some(number) => println!("{}", number),
      // Otherwise do nothing
      None => (),
    }
  \end{minted}
  \caption{Matching an Option}
  \label{lst:rust:match}
\end{listing}

\subsubsection{Traits}

A Trait defines behavior for an object that implements the Trait.
Traits are used to facilitate code reuse and polymorphism.

One integral trait in the Rust programming language is the Iterator trait defined in Listing \ref{lst:rust:iterator}.

\begin{listing}[H]
  \begin{minted}{rust}
    pub trait Iterator {
      type Item;
      fn next(&mut self) -> Option<Self::Item>;
      fn size_hint(&self) -> (usize, Option<usize) { (0, None) }
      // ...
    }
  \end{minted}
  \caption{Definition of Iterator trait}
  \label{lst:rust:iterator}
\end{listing}

Implementing the Iterator trait for the List type in Listing \ref{lst:rust:list-iter} involves the discussed features enums, pattern matching and traits.

\begin{listing}[H]
  \begin{minted}{rust}
    impl<T: Clone> Iterator for List<T> {
      type Item = T;

      fn next(&mut self) -> Option<T> {
        match self.clone() {
          Cons(val, next) => {
            *self = *next;
            Some(val)
          },
          Nil => None
        }
      }
    }
  \end{minted}
  \caption{Implementing the Iterator trait for the List type}
  \label{lst:rust:list-iter}
\end{listing}


\subsubsection{Loops}

Rust provides the two known loop constructs \textbf{for} and \textbf{while}, in addition to \textbf{loop} for infinite loops.
The \textbf{for} loop is not the conventional \textit{for (initialize; condition; increment)}, it operates on iterators.
To understand the functionality we look the approximate desugaring of the for loop into a loop and a match expression in Listing \ref{lst:rust:for}


\begin{minipage}[b]{0.5\linewidth}
  \begin{listing}[H]
  \begin{minted}{rust}

    let values = vec![1, 2, 3];
    for x in 0..10 {
      println!("{}", x);
    }

  \end{minted}
  \caption{Desugaring for loop}
  \label{lst:rust:for}
  \end{listing}
  \end{minipage}

\begin{minipage}[b]{0.5\linewidth}
  \begin{listing}[H]
    \begin{minted}{rust}

      let mut it = values.into_iter();
      loop {
        match it.next() {
          Some(x) => println!("{}", x),
          None => break,
        }
      }

    \end{minted}

    \caption{Desugaring for loop}
    \label{lst:rust:desugared-for}
  \end{listing}
\end{minipage}

\subsubsection{Case Study - Result}

The Result type is an integral type in the Rust library and in Rust code in general.
The type is the base type for error handling.

\begin{listing}[H]
  \begin{minted}{rust}
    #[must_use]
    pub enum Result<T, E> {
      Ok(T),
      Err(E),
    }
\end{minted}
\caption{Definition of Result}
\label{lst:rust:result}
\end{listing}

\subsection{Zero-cost Abstractions}
\label{chap:zero_cost_abstractions}

Abstractions, in the form of references and pointers to objects or structures and how they are
structured on the heap, is a common source of overhead in programming languages.
\autoref{fig:java_abstractions} \todo{Update with nicer figure} shows how Java lays out a vector of
strings in memory.
Fundamentally, a reference to the heap-allocated vector is placed on the stack, and the vector itself stores internal references to different strings that is placed elsewhere on the heap.
% There are four levels of indirection between the reference to the vector on stack, and the actual character data of its strings.
If we want to access the first character of a string stored in the vector, we would have to go through four levels of indirection - two objects need to be both dereferenced and indexed.
If the nesting of objects is deep it can result in many heap-lookups in order to get the desired data.

\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.5]{figures/java_abstractions}
  \end{center}
  \caption{Abstractions of a Vector of Strings in Java.}
  \label{fig:java_abstractions}
\end{figure}

An important part about zero-cost abstractions, is the ability to define new abstractions, like a vector, that optimize away to the bare minimal.
Rust introduces the same zero-cost abstractions that are present in C++, among other programming languages.
This is both important for performance, and in general, in order to have a deterministic and a common understanding of how the structures are laid out in the memory.
% when working with embedded devices.
% \todocite{This is a bogus sentence. Also, need to cite zero-cost abstraction articles}
\autoref{fig:cpp_abstractions} shows how C++ places a vector of strings in memory.
The main difference is that the vector itself is placed on the stack, and the string data is placed directly inside the memory block owned by the vector.
The important part of this example is that we are keeping the same level of abstraction, but there are only two layers of indirection between the vector and the character data.

There is still one really important difference between the two examples; we can safely have multiple references to our vector in Java without worrying about what would happen if its memory would grow and reallocate, whereas multiple references to our vector in C++ can certainly lead to dangling pointers if the vector is to reallocate when we are holding such a reference
\todo{Does this statement require further explanation? (i.e. explain why a reference to a stack-allocated vector in c++ can lead to a dangling pointer?}.
In Rust's case, all structures is allocated directly on the stack, if not explicitly told otherwise, which generally allows for faster access of data.
References to such stack-allocated variables can be passed around and accessed, just like in C++,
but Rust also introduces a set of rules that have to be followed in order to safely use these references.
These rules are based upon variable ownership and lifetimes, which are discussed in \autoref{sec:guaranteed_memory_safety}.
A Rust program will not successfully compile if the programmer is failing to properly maintain these rules.

\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.5]{figures/cpp_abstractions}
  \end{center}
  \caption{Abstractions of a Vector of Strings in Rust and C++.}
  \label{fig:cpp_abstractions}
\end{figure}

\subsection{Guaranteed memory safety}
\label{sec:guaranteed_memory_safety}

One of Rust's biggest features is full memory safety \cite{web:rust_book_unsafe} without sacrificing performance.
The memory safety boils down to how Rust manages its variables and their memory throughout the course of a program.
Rust introduces a few concepts that are all centered around the \emph{ownership} of these variables and their \emph{lifetimes}, and how references to these variables can be \emph{borrowed}.
These concepts are defined in Rust, but a lot of the inspiration behind those rules comes from other type-safe languages, like Haskell and OCaml, and especially Cyclone's \cite{Grossman2002,Swamy2006} region-based memory management.
Rust's ownership system are part of all the zero-cost abstractions mentioned in \autoref{chap:zero_cost_abstractions}, since all borrow-checking, and ownership- and lifetime-analysis are done statically during compilation.

\subsubsection{Ownership and Move Semantics}
\label{sec:back:rust:own}

In order to achieve full memory safety, we have to remove all form for memory leaks and dangling pointers to invalid memory.
This implies one \emph{memory deallocation} for every respective \emph{memory allocation}.
Traditionally, when allocating memory for a variable, the programming language will return a \emph{pointer},  or a \emph{handle}, that is essentially an address to a record in memory, together with how many bytes it takes to store that record in memory.
The memory can safely be deallocated when there is no longer any need for it, i.e. the variable holding the handle to the memory goes out of scope.

Modern programming languages, like Java and Python, typically achieves this with a Garbage Collector that runs while the program is being executed with the sole purpose of keeping the memory intact.
A common implementation is a reference counted garbage collector that keeps a count over the number of references to the variables and deallocates them when there are no valid references to them.
The downside of such an approach to memory safety is the continuous use of resources it requires to keep track all the references.
Every assignment to a variable and every time a variable enters a scope the reference count must be increased, and when it leaves a scope it must be decreased.

Another common implementation is a stop-the-world garbage collector.
It works differently, by regularly halting the executing program, before it recursively traces all references that are accessible from the \emph{root} set of variables, i.e. global variables, local variables in the stack and any variable that may be accessible from the current state of the registers \cite{Wilson1992}.
The memory that are accessible from these references are then marked as valid, and all the invalid memory will then be freed and accessible through new calls to the memory allocation function.
The downside of such an approach is the requirement of halting the entire program in order to release the invalid memory.
There are also many other techniques of garbage collection, that are often a variation of the ones already described, but they are all troublesome in constraint environments such as found on a small embedded device, or in real-time systems where the unpredictability of program execution introduced by a garbage collector is unacceptable.

Another approach to keeping track of the memory resources have been to give the programmer full control of every memory allocation and deallocation.
This is the most common approach for systems programming languages like C and C++, where performance and predictability is important.
However, it is easier to make the error of referencing invalid memory, or forgetting to free up memory that might lead the program to use all available resources over time.
Memory leaks like this will eventually lead a running program into crashing due to the unavailability of extra resources.

\todo{This subsection about GC and memory handling might be better suited in a different
background chapter}

It is important to always remember and deallocate all memory referenced by a handle, before the handle leaves its scope in the program.
Rust operates a little different from C when it comes to freeing memory, any variables holding a reference to stack- or heap-allocated memory will automatically be freed when it leaves the scope it lives in.
This is done statically without any interference by the programmer.
When the compiler sees that the owning handle for the allocated memory leaves its scope, it knows that it is also lost to the program, so it will insert a call to free the memory right after it becomes unreachable.
This eliminates the need for the programmer to manually do the memory bookkeeping.
These two aspects of memory allocation and deallocation is combined into the concept of \emph{ownership} that Rust incorporates.
When a handle that \emph{owns} a reference to a data-segment on the heap leaves its scope, Rust knows that it can safely free the memory that is referenced by it, because it is the \emph{owning handle} to that memory.

\begin{listing}[tb]
\begin{minted}{c}
fn read_book(b: Book) {
  println!("You just read {} pages", b.pages);
}

fn main() {
  // `b' is the owning handle to a Book
  let b = Book { pages: 150 };

  // when this line is reached, `read_book' takes ownership of `b'
  read_book(b);
  // when `read_book' returns, the book is also deallocated

  // this makes it impossible to  read the book two times
  read_book(b); // <- error: use of moved value: `b'
 }
\end{minted}
\caption{Example of an owned handle}
\label{lst:owning_handle}
\end{listing}

An example of this ownership is shown in \autoref{lst:owning_handle}.
There can only exist one owning handle for any heap- or a stack-allocated variable at any time during program execution.
This means that if the handle gets passed as an argument to a function, this function will take \emph{ownership} of the variable, by \emph{moving} it to the new scope defined by the function.
This move prevents any further use of the handle in its original scope and is necessary because Rust only allows one owned handle to any memory-segment at any time.
If two or more handles to the memory had existed at the same time it would have resulted in several calls to \texttt{free}, one for every time the handle left the different scopes.
The only way to continue using the handle in its original scope would have been to give the ownership back after using it.

\subsubsection{Borrowing}

\emph{Borrowing} is introduced as an alternative to moving the variable ownership across multiple scopes.
Rust allows the programmer to \emph{lend} away access to handles by passing a reference to the variable around instead of the actual handle.
There can exist multiple \emph{references} to the same place in memory, as long there is only one \emph{owner} of the actual handle.
A reference is denoted with an \texttt{\&} in front of the handle, this will tell Rust that we are working with a reference to the handle, or that we are borrowing the handle, to the end of the active scope.
Consider a modification of the previous example shown in \autoref{lst:borrowing_handle}.
Here, the the \texttt{read\_book} function is modified to accept a reference to a book instead of overtaking its ownership, this allows us to lend out the book to be read as many times as we want.
Since the book's owning handle lives in the scope defined by the main function, the memory will be deallocated when the program exits.

\begin{listing}[tb]
\begin{minted}{c}
fn read_book(b: &Book) {
  println!("You just read {} pages", b.pages);
}

fn main() {
  // `b' is the owning handle to a Book
  let b = Book { pages: 150 };

  // only a reference to the book is given to `read_book'
  read_book(&b);

  // it is possible to read the book two times, because `b'
  // still lives in the scope defined by the `main' function
  read_book(&b);
 }
\end{minted}
\caption{Example of borrowing}
\label{lst:borrowing_handle}
\end{listing}

\subsubsection{Lifetimes}

Rust needs a way to ensure that the memory used by all borrowed references to a handle is intact, i.e. that the references does not point to any deallocated memory.
Rust achieves this with a concept called \emph{lifetimes}, in which the compiler with the help of \emph{lifetime elisions} or \emph{lifetime specifiers}, can statically resolve any dangling pointers or \emph{use-after-free} issues introduced by the programmer.
Consider the example shown in \autoref{lst:invalid_ref_c}, of a function in \texttt{C} that returns a reference into a variable allocated in its own stackframe.
The \texttt{C} compiler is likely to issue a warning of such a serious mistake, but it will still compile the program.
A similar implementation of \texttt{name\_as\_ref} in \rust is shown in \autoref{lst:invalid_ref_rust}, but this will issue a compilation error because we try to return a reference without a lifetime specifier.

\begin{listing}[tb]
\begin{minted}{c}
char *name_as_ref() {
    Book b = { .name = "Gecko's", .pages = 150 };
    return &b.name;
}
\end{minted}
\caption{Returning an invalid reference in C}
\label{lst:invalid_ref_c}
\end{listing}

\begin{listing}[tb]
\begin{minted}{rust}
fn name_as_ref() -> &str { // <- error: missing lifetime specifier
    let b = Book { name: "Gecko's".to_string(), pages: 150 };
    &b.name
}
\end{minted}
\caption{Attempting to return an invalid reference in Rust}
\label{lst:invalid_ref_rust}
\end{listing}

\todo{Sentence is unclear? Needs rewrite?}
Lifetime elisions are applied to structures and trait declarations, among others, and they are described in function definitions in order to tell Rust that the named lifetime is valid in the scope in which the function-call is issued.
Such elisions are used extensively together with parameters and return values, and helps the compiler to reason about the liveliness of the references and whether they are valid or not.
There are two kinds of lifetimes; the ones associated with \emph{input parameters} to a function, and the ones associated with the \emph{returned value} from a function.
These are referred to as \emph{input-lifetimes} and \emph{output-lifetimes}, respectively.
We have an error if a function attempts to return a value with an output lifetime that lives shorter than the input lifetime, because this would result in a use-after-free.
As an example, consider the updated version of the \texttt{name\_as\_ref} function shown in \autoref{lst:valid_ref_rust}.
Here we annotate a lifetime by giving it the name \texttt{'a}, the explicit name of the lifetime does not matter, what matters is that we tell Rust that our function is passed a reference to a book that is alive \emph{before} the function is called.
Since Rust \emph{knows} that the book is alive before calling the function, it knows that it would be safe to return a reference to a field of that book because the returned value have the \emph{same} lifetime.

\begin{listing}[tb]
\begin{minted}{rust}
fn name_as_ref<'a>(b: &'a Book) -> &'a str {
    &b.name
}

fn main() {
  let b = Book { name: "Gecko's".to_string(), pages: 150 };
  let n = name_as_ref(&b);
}
\end{minted}
\caption{Retuning a reference with correct use of lifetime elisions}
\label{lst:valid_ref_rust}
\end{listing}

\subsection{Concurrency Model} % (fold)
\label{ssub:concurrency_model}

Solving both memory safety and concurrency might sound like two entirely different problems, but the ownership system described in \autoref{sec:guaranteed_memory_safety} actually turned out to go a long way of being the solution of them both \cite{web:fearless_concurrency_with_rust}.
While we do not utilize or focus on the concurrency of Rust in this project, it is still a very important feature for the language, so it will shortly describe parts of it in this section.

As already mentioned, Rust's ownership system helps us to reason about the liveliness of variables, and it helps us to catch errors like use-after-free, and data races by not allowing us to have multiple references to the same mutable data.
This makes it possible to describe and utilize many powerful idioms and paradigms, and concurrency models that are based on these core features of the language.
Thus, Rust's way of providing concurrency is made possible because the ownership system guarantees that it will be safe.
Indeed, the core concurrency functionality in Rust is merely an abstraction that is defined in the standard library, is is not a feature in the language itself.
This is an important distinction, because it allows for any number 3rd party concurrency libraries to evolve based on the same core principle of ownership, without being dependent on the concurrency idioms provided in the standard library.

\subsection{Unsafe Code} % (fold)
\label{ssub:unsafe_code}

Rust's strong type system and static guarantees about memory safety goes a long way of verifying the safety of programs, but for certain programs the restrictions set by the compiler might be too conservative.
There exists many programs that are indeed safe, but still not possible for the compiler to verify.
Examples of code that the compiler cannot verify is code that utilize \emph{raw pointers}, i.e. pointers to mutable data (like a C pointer), code that call directly \emph{into} external C libraries through Rust's \gls{ffi}, or code that can be called \emph{from} \gls{ffi}.

The ability to make new abstractions that optimize away to essentially nothing is an important feature of Rust.
Sometimes this means that the underlying code needs direct memory access and the ability to dereference raw pointers or call in to external libraries.
For these tasks, Rust provides a new keyword, \texttt{unsafe}.
It is important to note that this \texttt{unsafe} keyword is introduced in order to \emph{keep} Rust's semantics about memory safety, when the compiler can no longer guarantee it, it is up to the programmer to tell the compiler that the code inside the \texttt{unsafe} block is indeed safe.
\autoref{tab:reasons_for_unsafe} summarizes the three things that are possible to do in an \texttt{unsafe} block, and why the operations are considered unsafe.
It is important to notice that Rust's borrow checker is still active across the unsafe code, and that it will still issue errors during compilation if the rules about ownership is not withheld.

\begin{table}[ht]
\begin{center}
\begin{tabular}{p{4cm}|p{7cm}}
  \raggedleft{\textbf{Unsafe Operation}} &
  \textbf{Why it is considered unsafe}} \\
  \hline
  \raggedleft{Access and update static mutable variables} &
  Writing and reading to and from global state can lead to race conditions \\

  \raggedleft{Dereference raw pointers} &
  Raw pointers introduces memory aliasing to mutable data \\

  \raggedleft{Call unsafe functions \\ (e.g. over \gls{ffi})} &
  Rust can make no guarantees about the safety of \texttt{unsafe functions}. If a \gls{ffi} function is called we are leaving Rust and entering another language domain, it is not possible for Rust to verify the safety of such code. \\

\hline
\end{tabular}
\caption{Unsafe operations exposed through an \texttt{unsafe} block}
\label{tab:reasons_for_unsafe}
\end{center}
\end{table}

\subsection{Organization}
\label{ssub:rust:organization}

\subsubsection{Crates and Modules}

Rust provides two main features to organizing code, crates and modules.
A crate defines a collection of modules which constitutes a library.
The crate construct is a sharable part of rust code that can be included into other projects and libraries.
The module is the hierarchical means of organizing a crate.
Figure \ref{fig:rust:collections} shows a few or the modules contained within the Rust collection library.

\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.3]{figures/background/rust/libcollections.png}
  \end{center}
  \caption{Modules in collection crate.}
  \label{fig:rust:collections}
\end{figure}

\subsubsection{Rust library}

The Rust library is organized using crates.
This ensures that the design is modular and provides the programmer the ability to import only the components of the library that is needed for a given program.
The \texttt{Cargo} packages manager makes this feature easily exploitable.
Usually this facility is not needed when writing Rust programs, but when targeting embedded platforms barebones \todo{Bare metal?} this is integral to exploiting the standard library.
As the standard library contains functionality that assumes a operating system the library as a whole cannot be utilized.
Figure \ref{fig:rust:librust} depicts the crates of the standard library with their dependencies.

\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.3]{figures/background/rust/rust-lib.png}
  \end{center}
  \caption{Some crates of the rust library}
  \label{fig:rust:librust}
\end{figure}
std* - The std crate depends nearly all of the crates in the lower right corner

\subsection{Cargo}
\label{sec:cargo}

\texttt{Cargo} is Rust's package manager, a program that automates the process of building Rust programs.
It comes bundled with the default installation of Rust.
\texttt{Cargo} comes with a collection of tools that makes building, testing and running Rust programs a lot easier than invoking \texttt{rustc} directly.
\texttt{Cargo} also defines a standard Rust project layout, in addition to downloading and updating package dependencies.
This section will cover the most important features of \texttt{Cargo} and how it works that is required in order to understand the work that is described later in this project report.

\subsubsection{Project Structure}

Every crate, or package, built by \texttt{Cargo} requires a \texttt{Cargo.toml} file to be present in the root directory.
This file is interpreted by \texttt{Cargo} and is used to determine the name of the library and executables to be built in the package and what other packages that it depends on.
It also includes information that tells \texttt{Cargo} how the package can be compiled for different target architectures, and it is used to define different \textit{features} of a package - a way to conditionally compile certain parts of the code present in the library.

\begin{listing}
\dirtree{%
.1 hello\_world.
.2 Cargo.lock.
.2 Cargo.toml.
.2 build.rs.
.2 src.
.3 bin.
.4 hello\_mars.rs.
.4 hello\_jupiter.rs.
.3 lib.rs.
.3 main.rs.
.2 examples.
.3 hello\_venus.rs.
.2 tests.
.3 hello\_planets\_test.rs.
}
\caption{Cargo project structure}
\label{lst:cargo_project_structure}
\end{listing}

\autoref{lst:cargo_project_structure} shows a standard \texttt{Cargo} project structure.
The \texttt{lib.rs} file will be compiled into a crate with the project name, in this case it will be \texttt{hello\_world.rlib}.
If a \texttt{main.rs} file is present, it will be compiled into an executable with the same name.
Any files found under the \texttt{src/bin} directory will also be compiled into its own executables, \texttt{Cargo} will automatically link the \texttt{hello\_world} library and all of the package dependencies with these executables.

The \texttt{examples} directory contains different executables that demonstrates how to use the library, and finally the \texttt{tests} directory contains integration tests.
A package can also have it's own build-routine by specifying a \texttt{build} file in \texttt{Cargo.toml}, in this case we have a \texttt{build.rs} file present in the project.
This file is executed prior to building the library itself, and provides the possibility to e.g. compile and link third party C-libraries, or generate code prior to compilation.
Finally, \texttt{Cargo} also generates a \texttt{Cargo.lock} file that contains information about every package that are used by the project library and executables.
This file helps \texttt{Cargo} to determine if packages needs to be re-downloaded, updated or re-compiled in order for the package to behave correctly and be built consistently - independent on the target architecture it is built on and for.

\subsubsection{Building and testing (Or Tools?)}

As mentioned earlier, \texttt{Cargo} comes with a collection of tools that makes it easy to build and test Rust projects.
The most common commands are shown in \autoref{tab:common_cargo_commands}.
Most of these tools are self explanatory, but the \texttt{build} and the \texttt{test} commands will be described a little more thoroughly in this section.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|l}
\textbf{Command} & \textbf{Description}                           &
\hline
build  & Compile the current project                              &
clean  & Remove the target directory                              &
doc    & Build this project's and its dependencies' documentation &
new    & Create a new cargo project                               &
run    & Build and execute src/main.rs                            &
test   & Run the tests                                            &
bench  & Run the benchmarks                                       &
update & Update dependencies listed in Cargo.lock                 &
\hline
\end{tabular}
\caption{Common cargo commands}
\label{tab:common_cargo_commands}
\end{center}
\end{table}

By invoking the \texttt{cargo build} command, \texttt{Cargo} will download and resolve all package dependencies, and trigger \texttt{rustc} to compile them and link them with each other in the correct order.
When all dependencies have been built, the build script will be invoked (if it is present in the package), before the library itself is compiled.
Lastly, the projects executables will be compiled if the project contains a \texttt{main.rs} or sources in the \texttt{src/bin} directory.

The \texttt{cargo test} command will also trigger \texttt{rustc} to compile the library in the same manner as \texttt{cargo build}, but it will leave out compilation of the project executables.
When the library is compiled, any function that is marked with \texttt{\#[test]} will be included and treated like a unit test, this is a feature from Rust itself.
\texttt{Cargo} also treats all the sources found in the \texttt{examples} directory as tests, so these will be compiled instead of the other project executables, together with all the integration tests.
When \texttt{Cargo} has finished compiling the library and its executables, it will by default run all the unit tests, including the integration tests, but it will not run the examples.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|l}
\textbf{Flag} & \textbf{Description}                                   &
\hline
--features FEATURES   & Space-separated list of features to also build &
--target TRIPLE       & Build for the target triple                    &
\hline
\end{tabular}
\caption{Cargo flags to alter the package library and executables}
\label{tab:cargo_flags}
\end{center}
\end{table}

Both of these commands support several optional build-specific flags that are passed further on to the invocation of \texttt{rustc}, we will take extra notice to the two flags shown in \autoref{tab:cargo_flags}.
The \texttt{--target} flag is used if the project should be compiled for a different target architecture than the machine it is invoked on, this is necessary when cross-compiling the package.
The list following the \texttt{--features} flag will be used by \texttt{Cargo} and \texttt{rustc} to conditionally compile code that is present in the project.
Consider the example shown in \autoref{lst:rust_features} and its output shown in \autoref{tab:rust_features_output}.
We can see from this example that the definition of the \texttt{num} function will be different based on the feature flag that is passed together with \texttt{Cargo}.

\begin{listing}[H]
\begin{minted}{rust}
// src/main.rs
#[cfg(feature = "one")]
fn num() -> u32 { 1 }

#[cfg(feature = "two")]
fn num() -> u32 { 2 }

fn main() {
    println!("num() + num() = {}", num() + num())
}
\end{minted}
\caption{Example usage of features}
\label{lst:rust_features}
\end{listing}

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|l}
\textbf{Command} & \textbf{Output}                          &
\hline
\texttt{\$ cargo build --features one}  & num() + num() = 2 &
\texttt{\$ cargo build --features two}  & num() + num() = 4 &
\hline
\end{tabular}
\caption{Example output of features}
\label{tab:rust_features_output}
\end{center}
\end{table}
